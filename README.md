# ai_ml_elevate_labs_task1

This task focuses on cleaning and preparing the Titanic dataset for machine learning. First, the dataset is loaded into Python using Pandas and explored to understand its structure, data types, and missing values. Missing data is handled by filling in gaps with averages or the most common values, ensuring the dataset is complete. Text columns such as "Sex" and "Embarked" are converted into numbers so that machine learning algorithms can process them. Numerical features like "Age" and "Fare" are scaled to bring them onto similar ranges, making the data easier for models to learn from. Outliers, or unusual data points, are detected using visualizations like boxplots and removed to improve model performance.

Throughout the process, tools such as Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, and SciPy are used to make the data clean, consistent, and ready for analysis and modeling.
